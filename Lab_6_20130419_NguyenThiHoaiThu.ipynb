{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NguyenThiHoaiThu20130419/ML2023_TV201/blob/main/Lab_6_20130419_NguyenThiHoaiThu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to deal with classification task using **Random Forests** and **Na√Øve Bayes** algorithms with/without **Feature Selection**. \n",
        "\n",
        "*   **Deadline: 23:59, 25/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "from sklearn import datasets\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn import metrics\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.feature_selection import SelectKBest, SelectFromModel\n",
        "from sklearn.feature_selection import chi2, f_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "Task 1. Compare the performance of selected classification algorithms including **Random forest**, **NaiveBayes**, and **SVM** with **mnist** dataset based on **accuracy, precision, recall, f1** measures according to **without using selection feature** and **using selection feature**.\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = datasets.load_digits()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "Ct54PexOJTEa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "# Random forest\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "accuracy_rf = accuracy_score(y_pred_rf, y_test)\n",
        "precision_rf = precision_score(y_pred_rf, y_test, average='macro')\n",
        "recall_rf = recall_score(y_pred_rf, y_test, average='macro')\n",
        "f1_rf = f1_score(y_pred_rf, y_test, average='macro')\n",
        "\n",
        "# NaiveBayes\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "\n",
        "accuracy_nb = accuracy_score(y_pred_nb, y_test)\n",
        "precision_nb = precision_score(y_pred_nb, y_test, average='macro')\n",
        "recall_nb = recall_score(y_pred_nb, y_test, average='macro')\n",
        "f1_nb = f1_score(y_pred_nb, y_test, average='macro')\n",
        "\n",
        "# SVM\n",
        "svm_linear = SVC(kernel='linear')\n",
        "svm_linear.fit(X_train, y_train)\n",
        "y_pred_svm = svm_linear.predict(X_test)\n",
        "\n",
        "accuracy_svm = accuracy_score(y_pred_svm, y_test)\n",
        "precision_svm = precision_score(y_pred_svm, y_test, average='macro')\n",
        "recall_svm = recall_score(y_pred_svm, y_test, average='macro')\n",
        "f1_svm = f1_score(y_pred_svm, y_test, average='macro')\n",
        "\n",
        "# Bang so sanh\n",
        "tb = PrettyTable(['Algorithm', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "\n",
        "tb.add_row(['Random forest', accuracy_rf, precision_rf, recall_rf, f1_rf])\n",
        "tb.add_row(['NaiveBayes', accuracy_nb, precision_nb, recall_nb, f1_nb])\n",
        "tb.add_row(['SVM', accuracy_svm, precision_svm, recall_svm, f1_svm])\n",
        "\n",
        "print('Without using selection feature')\n",
        "print(tb)"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf00647-26f9-4272-a423-a6310eaaa17b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without using selection feature\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|   Algorithm   |      Accuracy      |     Precision      |       Recall       |         F1         |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "| Random forest | 0.9740740740740741 | 0.974121406737868  | 0.9736398154687904 | 0.9737289452823499 |\n",
            "|   NaiveBayes  | 0.8518518518518519 | 0.8492283225937289 | 0.8668799024332581 | 0.8475555476524305 |\n",
            "|      SVM      | 0.9796296296296296 | 0.980370817623084  | 0.9796545379907448 | 0.9799391234329768 |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Xuat ra muc do quan trong cua cac thuoc tinh, sau do sap xep theo thu tu giam dan\n",
        "feature_imp = pd.Series(rf.feature_importances_,index=mnist.feature_names).sort_values(ascending=False)\n",
        "print(feature_imp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv0Fk3CELEnN",
        "outputId": "fe5aacb7-bac8-4e10-ccd2-d61fafbcf50a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pixel_2_5    0.044027\n",
            "pixel_3_2    0.042428\n",
            "pixel_4_4    0.041806\n",
            "pixel_5_3    0.039875\n",
            "pixel_5_2    0.035736\n",
            "               ...   \n",
            "pixel_2_0    0.000013\n",
            "pixel_3_7    0.000012\n",
            "pixel_0_0    0.000000\n",
            "pixel_4_7    0.000000\n",
            "pixel_4_0    0.000000\n",
            "Length: 64, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "sfm = SelectFromModel(rf, threshold=0.001)\n",
        "X_train = sfm.fit_transform(X_train, y_train)\n",
        "X_test = sfm.transform(X_test)\n",
        "\n",
        "# Random forest\n",
        "rf = RandomForestClassifier(n_estimators=100) \n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "accuracy_rf = accuracy_score(y_pred_rf, y_test)\n",
        "precision_rf = precision_score(y_pred_rf, y_test, average='macro')\n",
        "recall_rf = recall_score(y_pred_rf, y_test, average='macro')\n",
        "f1_rf = f1_score(y_pred_rf, y_test, average='macro')\n",
        "\n",
        "# NaiveBayes \n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "\n",
        "accuracy_nb = accuracy_score(y_pred_nb, y_test)\n",
        "precision_nb = precision_score(y_pred_nb, y_test, average='macro')\n",
        "recall_nb = recall_score(y_pred_nb, y_test, average='macro')\n",
        "f1_nb = f1_score(y_pred_nb, y_test, average='macro')\n",
        "\n",
        "# SVM\n",
        "svm_ln = SVC(kernel = 'linear')\n",
        "svm_ln.fit(X_train, y_train)\n",
        "y_pred_svm = svm_ln.predict(X_test)\n",
        "\n",
        "accuracy_svm = accuracy_score(y_pred_svm, y_test)\n",
        "precision_svm = precision_score(y_pred_svm, y_test, average='macro')\n",
        "recall_svm = recall_score(y_pred_svm, y_test, average='macro')\n",
        "f1_svm = f1_score(y_pred_svm, y_test, average='macro')\n",
        "\n",
        "# Bang so sanh\n",
        "tb1 = PrettyTable(['Algorithm', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "\n",
        "tb1.add_row(['Random forest', accuracy_rf, precision_rf, recall_rf, f1_rf])\n",
        "tb1.add_row(['NaiveBayes', accuracy_nb, precision_nb, recall_nb, f1_nb])\n",
        "tb1.add_row(['SVM', accuracy_svm, precision_svm, recall_svm, f1_svm])\n",
        "\n",
        "print('Using selection feature')\n",
        "print(tb1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZYvUXDtna2k",
        "outputId": "fa0ac085-b597-42ee-ec62-08eeea3c0fd4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using selection feature\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|   Algorithm   |      Accuracy      |     Precision      |       Recall       |         F1         |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "| Random forest | 0.9703703703703703 | 0.9705713146217381 | 0.969721128944063  | 0.9700089576719026 |\n",
            "|   NaiveBayes  | 0.8574074074074074 | 0.8541128566618914 | 0.8636893139936923 | 0.8502278537358784 |\n",
            "|      SVM      | 0.9796296296296296 | 0.980370817623084  | 0.9796545379907448 | 0.9799391234329768 |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "For given bank dataset (bank.csv) having the following attributes :\n",
        "1.\t**age** (numeric)\n",
        "2.\t**job** : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
        "3.\t**marital** : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
        "4.\t**education** (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
        "5.\t**default**: has credit in default? (categorical: 'no','yes','unknown')\n",
        "6.\t**housing**: has housing loan? (categorical: 'no','yes','unknown')\n",
        "7.\t**loan**: has personal loan? (categorical: 'no','yes','unknown')\n",
        "8.\t**contact**: contact communication type (categorical: 'cellular','telephone')\n",
        "9.\t**month**: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
        "10.\t**day_of_week**: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
        "11.\t**duration**: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
        "12.\t**campaign**: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "13.\t**pdays**: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
        "14.\t**previous**: number of contacts performed before this campaign and for this client (numeric)\n",
        "15.\t**poutcome**: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
        "Output variable (desired target):\n",
        "16.\t**y**. has the client subscribed a term deposit? (binary: 'yes','no')\n",
        "\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import thu vien\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/ML2023_TV201'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aw65rJxGNR_",
        "outputId": "cccb0258-e291-44d2-9b94-9aaab5bc1d20"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/ML2023_TV201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bank = pd.read_csv('bank.csv')\n",
        "bank.columns\n",
        "#print(bank)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujwunApSGhDY",
        "outputId": "dd2f1dff-0742-4088-ff1a-7d1f816d7684"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
              "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
              "       'previous', 'poutcome', 'deposit'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.1. Apply StandardScaler() function to columns that contains numerical data ('age', 'balance', 'day', 'campaign', 'pdays', 'previous')"
      ],
      "metadata": {
        "id": "q89LEvT7dqaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "# Chuan hoa du lieu\n",
        "scaler = StandardScaler()\n",
        "bank[['age', 'balance', 'day', 'campaign',  'pdays', 'previous']] = scaler.fit_transform(bank[['age', 'balance', 'day', 'campaign',  'pdays', 'previous']])\n",
        "print(bank[['age', 'balance', 'day', 'campaign',  'pdays', 'previous']])"
      ],
      "metadata": {
        "id": "8vx3mfIidu4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b2bf9d-8ed8-4e42-82d9-34dbbeb311d3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            age   balance       day  campaign     pdays  previous\n",
            "0      1.491505  0.252525 -1.265746 -0.554168 -0.481184 -0.363260\n",
            "1      1.239676 -0.459974 -1.265746 -0.554168 -0.481184 -0.363260\n",
            "2     -0.019470 -0.080160 -1.265746 -0.554168 -0.481184 -0.363260\n",
            "3      1.155733  0.293762 -1.265746 -0.554168 -0.481184 -0.363260\n",
            "4      1.071790 -0.416876 -1.265746 -0.186785 -0.481184 -0.363260\n",
            "...         ...       ...       ...       ...       ...       ...\n",
            "11157 -0.691015 -0.473616  0.515650 -0.554168 -0.481184 -0.363260\n",
            "11158 -0.187357 -0.246658  0.040612  0.547981 -0.481184 -0.363260\n",
            "11159 -0.774958 -0.464934  0.396891 -0.186785 -0.481184 -0.363260\n",
            "11160  0.148416 -0.473926 -0.909466 -0.186785  1.109571  1.818332\n",
            "11161 -0.607072 -0.473926 -0.790707 -0.554168 -0.481184 -0.363260\n",
            "\n",
            "[11162 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.2. Apply Encode Categorical Value (OneHotEncoder) to transfrom categorical data to numerical data ('job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome')"
      ],
      "metadata": {
        "id": "r7acR0TxdvY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoded_cols = encoder.fit_transform(bank[columns])\n",
        "encoded_df = pd.DataFrame(encoded_cols, columns=encoder.get_feature_names_out(columns))\n",
        "data_encoded = pd.concat([bank, encoded_df], axis=1)\n",
        "data_encoded.drop(columns, axis=1, inplace=True)\n",
        "\n",
        "print(data_encoded.head(5))"
      ],
      "metadata": {
        "id": "egtgBmAtd0um",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f37c0660-c4ce-4db6-84c2-455f6a7bbdad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        age   balance       day  duration  campaign     pdays  previous  \\\n",
            "0  1.491505  0.252525 -1.265746      1042 -0.554168 -0.481184  -0.36326   \n",
            "1  1.239676 -0.459974 -1.265746      1467 -0.554168 -0.481184  -0.36326   \n",
            "2 -0.019470 -0.080160 -1.265746      1389 -0.554168 -0.481184  -0.36326   \n",
            "3  1.155733  0.293762 -1.265746       579 -0.554168 -0.481184  -0.36326   \n",
            "4  1.071790 -0.416876 -1.265746       673 -0.186785 -0.481184  -0.36326   \n",
            "\n",
            "  deposit  job_admin.  job_blue-collar  ...  month_jun  month_mar  month_may  \\\n",
            "0     yes         1.0              0.0  ...        0.0        0.0        1.0   \n",
            "1     yes         1.0              0.0  ...        0.0        0.0        1.0   \n",
            "2     yes         0.0              0.0  ...        0.0        0.0        1.0   \n",
            "3     yes         0.0              0.0  ...        0.0        0.0        1.0   \n",
            "4     yes         1.0              0.0  ...        0.0        0.0        1.0   \n",
            "\n",
            "   month_nov  month_oct  month_sep  poutcome_failure  poutcome_other  \\\n",
            "0        0.0        0.0        0.0               0.0             0.0   \n",
            "1        0.0        0.0        0.0               0.0             0.0   \n",
            "2        0.0        0.0        0.0               0.0             0.0   \n",
            "3        0.0        0.0        0.0               0.0             0.0   \n",
            "4        0.0        0.0        0.0               0.0             0.0   \n",
            "\n",
            "   poutcome_success  poutcome_unknown  \n",
            "0               0.0               1.0  \n",
            "1               0.0               1.0  \n",
            "2               0.0               1.0  \n",
            "3               0.0               1.0  \n",
            "4               0.0               1.0  \n",
            "\n",
            "[5 rows x 52 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.3. Apply **Decision tree, Random forest, kNN, Na√ØveBayes** to preproceed dataset in the previous steps. Then compare the obtained results using **accuracy, precision, recall, f1** measures."
      ],
      "metadata": {
        "id": "K2Si6d69d1nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chuyen doi bien doc lap dang chuoi sang dang so\n",
        "X = pd.get_dummies(bank.drop('deposit', axis=1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, bank['deposit'], test_size=0.3, random_state=3)"
      ],
      "metadata": {
        "id": "jkSFzTbFJCbf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "# Decision tree\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(X_train, y_train)\n",
        "y_pred_tree = tree.predict(X_test)\n",
        "\n",
        "acc_tree = accuracy_score(y_pred_tree, y_test)\n",
        "precision_tree = precision_score(y_pred_tree, y_test, average='macro')\n",
        "recall_tree = recall_score(y_pred_tree, y_test, average='macro')\n",
        "f1_tree = f1_score(y_pred_tree, y_test, average='macro')\n",
        "\n",
        "# Random forest\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "acc_rf = accuracy_score(y_pred_rf, y_test)\n",
        "precision_rf = precision_score(y_pred_rf, y_test, average='macro')\n",
        "recall_rf = recall_score(y_pred_rf, y_test, average='macro')\n",
        "f1_rf = f1_score(y_pred_rf, y_test, average='macro')\n",
        "\n",
        "# kNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "acc_knn = accuracy_score(y_pred_knn, y_test)\n",
        "precision_knn = precision_score(y_pred_knn, y_test, average='macro')\n",
        "recall_knn = recall_score(y_pred_knn, y_test, average='macro')\n",
        "f1_knn = f1_score(y_pred_knn, y_test, average='macro')\n",
        "\n",
        "# NaiveBayes\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "\n",
        "acc_nb = accuracy_score(y_pred_nb, y_test)\n",
        "precision_nb = precision_score(y_pred_nb, y_test, average='macro')\n",
        "recall_nb = recall_score(y_pred_nb, y_test, average='macro')\n",
        "f1_nb = f1_score(y_pred_nb, y_test, average='macro')\n",
        "\n",
        "# Bang so sanh\n",
        "tb = PrettyTable(['Algorithm', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "\n",
        "tb.add_row(['Decision tree', acc_tree, precision_tree, recall_tree, f1_tree])\n",
        "tb.add_row(['Random forest', acc_rf, precision_rf, recall_rf, f1_rf])\n",
        "tb.add_row(['kNN', acc_knn, precision_knn, recall_knn, f1_knn])\n",
        "tb.add_row(['NaiveBayes', acc_nb, precision_nb, recall_nb, f1_nb])\n",
        "\n",
        "print('Without using selection feature')\n",
        "print(tb)"
      ],
      "metadata": {
        "id": "Ouil-cf_d8jW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "506f12a2-5164-4051-ae2d-d700ec1d08de"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without using selection feature\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|   Algorithm   |      Accuracy      |     Precision      |       Recall       |         F1         |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "| Decision tree | 0.7856076440728575 | 0.7841001413718438 | 0.7851330925225077 | 0.7844916344916344 |\n",
            "| Random forest | 0.846521349656614  | 0.8482922639179685 | 0.8471776869233898 | 0.8464561717735375 |\n",
            "|      kNN      | 0.7656016721409376 | 0.7644328125838835 | 0.7648253992604774 | 0.764604244683401  |\n",
            "|   NaiveBayes  | 0.7049865631531801 | 0.6960711154059519 | 0.718196674430683  | 0.6937680241963846 |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.4. Using selection feature to above dataset, then compare the classification results with those in Task 2.3. "
      ],
      "metadata": {
        "id": "SweVRB4meApP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "sfm = SelectFromModel(rf, threshold=0.001)\n",
        "X_train = sfm.fit_transform(X_train, y_train)\n",
        "X_test = sfm.transform(X_test)\n",
        "\n",
        "# Decision tree\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(X_train, y_train)\n",
        "y_pred_tree = tree.predict(X_test)\n",
        "\n",
        "acc_tree = accuracy_score(y_pred_tree, y_test)\n",
        "precision_tree = precision_score(y_pred_tree, y_test, average='macro')\n",
        "recall_tree = recall_score(y_pred_tree, y_test, average='macro')\n",
        "f1_tree = f1_score(y_pred_tree, y_test, average='macro')\n",
        "\n",
        "# Random forest\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "acc_rf = accuracy_score(y_pred_rf, y_test)\n",
        "precision_rf = precision_score(y_pred_rf, y_test, average='macro')\n",
        "recall_rf = recall_score(y_pred_rf, y_test, average='macro')\n",
        "f1_rf = f1_score(y_pred_rf, y_test, average='macro')\n",
        "\n",
        "# kNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "acc_knn = accuracy_score(y_pred_knn, y_test)\n",
        "precision_knn = precision_score(y_pred_knn, y_test, average='macro')\n",
        "recall_knn = recall_score(y_pred_knn, y_test, average='macro')\n",
        "f1_knn = f1_score(y_pred_knn, y_test, average='macro')\n",
        "\n",
        "# NaiveBayes\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "\n",
        "acc_nb = accuracy_score(y_pred_nb, y_test)\n",
        "precision_nb = precision_score(y_pred_nb, y_test, average='macro')\n",
        "recall_nb = recall_score(y_pred_nb, y_test, average='macro')\n",
        "f1_nb= f1_score(y_pred_nb, y_test, average='macro')\n",
        "\n",
        "# Bang so sanh\n",
        "tb2 = PrettyTable(['Algorithm', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "\n",
        "tb2.add_row(['Decision tree', acc_tree, precision_tree, recall_tree, f1_tree])\n",
        "tb2.add_row(['Random forest', acc_rf, precision_rf, recall_rf, f1_rf])\n",
        "tb2.add_row(['kNN', acc_knn, precision_knn, recall_knn, f1_knn])\n",
        "tb2.add_row(['NaiveBayes', acc_nb, precision_nb, recall_nb, f1_nb])\n",
        "\n",
        "print('Using selection feature')\n",
        "print(tb2)"
      ],
      "metadata": {
        "id": "seFBhqCSeC7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "845f18dd-1044-4ac2-d552-05e9813fd759"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using selection feature\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|   Algorithm   |      Accuracy      |     Precision      |       Recall       |         F1         |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
            "| Decision tree | 0.7876978202448492 | 0.786607254701956  | 0.7870327623706588 | 0.7867944177960485 |\n",
            "| Random forest | 0.8477157360406091 | 0.8496689393532686 | 0.8486382662874556 | 0.8476684575538336 |\n",
            "|      kNN      | 0.7656016721409376 | 0.7644328125838835 | 0.7648253992604774 | 0.764604244683401  |\n",
            "|   NaiveBayes  | 0.7049865631531801 | 0.6960711154059519 | 0.718196674430683  | 0.6937680241963846 |\n",
            "+---------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "For a given dataset in the Lab #5 (**credit card dataset**), perform feature selection and thencompare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression, SVM, Random Forest and NaiveBayes) based on accuracy, precision, recall, f1 measures.\n"
      ],
      "metadata": {
        "id": "Z5pp7_h-aP2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "credit_card = pd.read_csv('creditcard.csv')\n",
        "#print(credit_card.columns)\n",
        "X = credit_card.drop('Class', axis=1)\n",
        "y = credit_card['Class']"
      ],
      "metadata": {
        "id": "y0nf1VTOVBYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chuan hoa du lieu\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=7)"
      ],
      "metadata": {
        "id": "Bnq5oh-dVH6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random forest without using selection feature\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf_fs = rf.predict(X_test)\n",
        "\n",
        "acc_rf = accuracy_score(y_pred_rf, y_test)\n",
        "precision_rf = precision_score(y_pred_rf, y_test, average='macro')\n",
        "recall_rf = recall_score(y_pred_rf, y_test, average='macro')\n",
        "f1_rf = f1_score(y_pred_rf, y_test, average='macro')"
      ],
      "metadata": {
        "id": "V6UXC4XyYShq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "sfm = SelectFromModel(rf, threshold=0.001)\n",
        "X_train = sfm.fit_transform(X_train, y_train)\n",
        "X_test = sfm.transform(X_test)\n",
        "# Decision tree\n",
        "tree = DecisionTreeClassifier(criterion=\"gini\", random_state=7, max_depth=3, min_samples_leaf=5)\n",
        "tree.fit(X_train, y_train)\n",
        "y_pred_tree = tree.predict(X_test)\n",
        "\n",
        "acc_tree = accuracy_score(y_pred_tree, y_test)\n",
        "precision_tree = precision_score(y_pred_tree, y_test, average='macro')\n",
        "recall_tree = recall_score(y_pred_tree, y_test, average='macro')\n",
        "f1_tree = f1_score(y_pred_tree, y_test, average='macro')\n",
        "\n",
        "# kNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "acc_knn = accuracy_score(y_pred_knn, y_test)\n",
        "precision_knn = precision_score(y_pred_knn, y_test, average='macro')\n",
        "recall_knn = recall_score(y_pred_knn, y_test, average='macro')\n",
        "f1_knn = f1_score(y_pred_knn, y_test, average='macro')\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "acc_lr = accuracy_score(y_pred_lr, y_test)\n",
        "precision_lr = precision_score(y_pred_lr, y_test, average='macro')\n",
        "recall_lr = recall_score(y_pred_lr, y_test, average='macro')\n",
        "f1_lr = f1_score(y_pred_lr, y_test, average='macro')\n",
        "\n",
        "# SVM\n",
        "svm_ln = SVC(kernel = 'linear')\n",
        "svm_ln.fit(X_train, y_train)\n",
        "y_pred_svm = svm_ln.predict(X_test)\n",
        "\n",
        "acc_svm = accuracy_score(y_pred_svm, y_test)\n",
        "precision_svm = precision_score(y_pred_svm, y_test, average='macro')\n",
        "recall_svm = recall_score(y_pred_svm, y_test, average='macro')\n",
        "f1_svm = f1_score(y_pred_svm, y_test, average='macro')\n",
        "\n",
        "# Random forest\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "acc_rf = accuracy_score(y_pred_rf, y_test)\n",
        "precision_rf = precision_score(y_pred_rf, y_test, average='macro')\n",
        "recall_rf = recall_score(y_pred_rf, y_test, average='macro')\n",
        "f1_rf = f1_score(y_pred_rf, y_test, average='macro')\n",
        "\n",
        "# NaiveBayes\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "\n",
        "acc_nb = accuracy_score(y_pred_nb, y_test)\n",
        "precision_nb = precision_score(y_pred_nb, y_test, average='macro')\n",
        "recall_nb = recall_score(y_pred_nb, y_test, average='macro')\n",
        "f1_nb = f1_score(y_pred_nb, y_test, average='macro')\n",
        "\n",
        "# Bang so sanh\n",
        "tb3 = PrettyTable(['Algorithm', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "\n",
        "tb3.add_row(['Decision tree', acc_tree, precision_tree, recall_tree, f1_tree])\n",
        "tb3.add_row(['kNN', acc_knn, precision_knn, recall_knn, f1_knn])\n",
        "tb3.add_row(['Logistic Regression', acc_lr, precision_lr, recall_lr, f1_lr])\n",
        "tb3.add_row(['SVM', acc_svm, precision_svm, recall_svm, f1_svm])\n",
        "tb3.add_row(['Random forest', acc_rf, precision_rf, recall_rf, f1_rf])\n",
        "tb3.add_row(['NaiveBayes', acc_nb, precision_nb, recall_nb, f1_nb])\n",
        "\n",
        "print('Using selection feature')\n",
        "print(tb3)"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06775e08-2d64-4a29-d455-65538b360ed3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using selection feature\n",
            "+---------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|      Algorithm      |      Accuracy      |     Precision      |       Recall       |         F1         |\n",
            "+---------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|    Decision tree    | 0.7656016721409376 | 0.7716619244465919 | 0.7789250261089026 | 0.7648606850328212 |\n",
            "|         kNN         | 0.7656016721409376 | 0.7644328125838835 | 0.7648253992604774 | 0.764604244683401  |\n",
            "| Logistic Regression | 0.8193490594207226 | 0.8180501422666022 | 0.8190472326678677 | 0.8184474966857391 |\n",
            "|         SVM         |  0.8250223947447   | 0.824758504679587  | 0.8243429259766302 | 0.8245210912966658 |\n",
            "|    Random forest    | 0.8450283666766198 | 0.8473103559349331 | 0.8465215807685303 | 0.8450062559071306 |\n",
            "|      NaiveBayes     | 0.7049865631531801 | 0.6960711154059519 | 0.718196674430683  | 0.6937680241963846 |\n",
            "+---------------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}