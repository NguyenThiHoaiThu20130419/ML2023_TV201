{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NguyenThiHoaiThu20130419/ML2023_TV201/blob/main/Lab_5_20130419_NguyenThiHoaiThu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to deal with **SVM** to classification tasks and compare its performance with other competitive algorithms. In general, **SVM** is one of the most popular and widely used supervised machine learning algorithms.\n",
        "\n",
        "*   **Deadline: 23:59, 17/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/ML2023_TV201'"
      ],
      "metadata": {
        "id": "dtaoXZQz31YT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "911a33f1-e39b-4ef0-c00a-6fd53d50c5e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/ML2023_TV201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "For breast cancer dataset (https://tinyurl.com/3vme8hr3) which could be loaded from datasets in sklearn as follows:\n",
        "\n",
        "```\n",
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "\n",
        "#Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "```\n",
        "\n",
        "*   1.1.\tApply SVM algorithm to above dataset using linear kernel.\n",
        "*   1.2.\tCompare the obtained results with other competitive algorithms (Logistic Regression, Decision Tree, kNN) based on metrics: accuracy, precision, recall, f1 measures.\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "cancer = datasets.load_breast_cancer()\n",
        "x = cancer.data\n",
        "y = cancer.target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)\n",
        "# svm\n",
        "clf = svm.SVC(kernel = 'linear')\n",
        "clf.fit(x_train, y_train)\n",
        "y_pred_svm = clf.predict(x_test)\n",
        "\n",
        "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "precision_svm = precision_score(y_test, y_pred_svm, average = 'macro')\n",
        "recall_svm = recall_score(y_test, y_pred_svm, average = 'macro')\n",
        "f1_svm = f1_score(y_test, y_pred_svm, average = 'macro')\n",
        "\n",
        "# Logistic Regression\n",
        "logistic = LogisticRegression()\n",
        "logistic.fit(x_train, y_train)\n",
        "y_pred_logistic = logistic.predict(x_test)\n",
        "\n",
        "acc_logistic = accuracy_score(y_test, y_pred_logistic)\n",
        "precision_logistic = precision_score(y_test, y_pred_logistic, average = 'macro')\n",
        "recall_logistic = recall_score(y_test, y_pred_logistic, average = 'macro')\n",
        "f1_logistic = f1_score(y_test, y_pred_logistic, average = 'macro')\n",
        "\n",
        "# Decision Tree\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(x_train, y_train)\n",
        "y_pred_tree = tree.predict(x_test)\n",
        "\n",
        "acc_tree = accuracy_score(y_test, y_pred_tree)\n",
        "precision_tree = precision_score(y_test, y_pred_tree, average = 'macro')\n",
        "recall_tree = recall_score(y_test, y_pred_tree, average = 'macro')\n",
        "f1_tree = f1_score(y_test, y_pred_tree, average = 'macro')\n",
        "\n",
        "# kNN\n",
        "kNN = KNeighborsClassifier()\n",
        "kNN.fit(x_train, y_train)\n",
        "y_pred_kNN = kNN.predict(x_test)\n",
        "\n",
        "acc_kNN = accuracy_score(y_test, y_pred_kNN)\n",
        "precision_kNN = precision_score(y_test, y_pred_kNN, average = 'macro')\n",
        "recall_kNN = recall_score(y_test, y_pred_kNN, average = 'macro')\n",
        "f1_kNN = f1_score(y_test, y_pred_kNN, average = 'macro')\n",
        "\n",
        "# Tao bang so sanh cac metrics Accuracy, Precision, Recall, F1\n",
        "table = PrettyTable(['Thuat toan', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "\n",
        "table.add_row(['SVM', acc_svm, precision_svm, recall_svm, f1_svm])\n",
        "table.add_row(['Logistic', acc_logistic, precision_logistic, recall_logistic, f1_logistic])\n",
        "table.add_row(['Tree', acc_tree, precision_tree, recall_tree, f1_tree])\n",
        "table.add_row(['kNN', acc_kNN, precision_kNN, recall_kNN, f1_kNN])\n",
        "\n",
        "print(table)"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11007808-c0dd-41b8-f26e-66f5ffd3475d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------------------+--------------------+--------------------+--------------------+\n",
            "| Thuat toan |      Accuracy      |     Precision      |       Recall       |         F1         |\n",
            "+------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|    SVM     | 0.9649122807017544 | 0.9727272727272727 | 0.9552238805970149 | 0.962543808411215  |\n",
            "|  Logistic  | 0.9415204678362573 | 0.9472429210134128 | 0.9306831228473019 | 0.9375730140186915 |\n",
            "|    Tree    | 0.935672514619883  | 0.9391092039064812 | 0.9258754305396096 | 0.9315427448411399 |\n",
            "|    kNN     | 0.9532163742690059 | 0.9563492063492063 | 0.9456084959816302 | 0.9503628447024675 |\n",
            "+------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "\n",
        "*   1.1.\tPerform SVM algorithm to **Iris dataset** using **linear kernel**.\n",
        "*   1.2.\tCompare the obtained results in 1.1 with SVM using other kernels (**Polynomial Kernel, Gaussian Kernel, Sigmoid Kernel, Radial Basis Function Kernel**). Some metrics could be used: accuracy, precision, recall, f1 measures\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S43IoUT-0OQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "iris = datasets.load_iris()\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)\n",
        "# Linear kernel\n",
        "clf_ln = svm.SVC(kernel = 'linear')\n",
        "clf_ln.fit(x_train, y_train)\n",
        "y_pred_ln = clf_ln.predict(x_test)\n",
        "\n",
        "acc_ln = accuracy_score(y_test, y_pred_ln)\n",
        "precision_ln = precision_score(y_test, y_pred_ln, average = 'macro')\n",
        "recall_ln = recall_score(y_test, y_pred_ln, average = 'macro')\n",
        "f1_ln = f1_score(y_test, y_pred_ln, average = 'macro')\n",
        "\n",
        "# Polynomial Kernel\n",
        "clf_poly = svm.SVC(kernel = 'poly')\n",
        "clf_poly.fit(x_train, y_train)\n",
        "y_pred_poly = clf_poly.predict(x_test)\n",
        "\n",
        "acc_poly = accuracy_score(y_test, y_pred_poly)\n",
        "precision_poly = precision_score(y_test, y_pred_poly, average = 'macro')\n",
        "recall_poly = recall_score(y_test, y_pred_poly, average = 'macro')\n",
        "f1_poly = f1_score(y_test, y_pred_poly, average = 'macro')\n",
        "\n",
        "# Gaussian Kernel\n",
        "clf_rbf = svm.SVC(kernel = 'rbf')\n",
        "clf_rbf.fit(x_train, y_train)\n",
        "y_pred_rbf = clf_rbf.predict(x_test)\n",
        "\n",
        "acc_rbf = accuracy_score(y_test, y_pred_rbf)\n",
        "precision_rbf = precision_score(y_test, y_pred_rbf, average = 'macro')\n",
        "recall_rbf = recall_score(y_test, y_pred_rbf, average = 'macro')\n",
        "f1_rbf = f1_score(y_test, y_pred_rbf, average = 'macro')\n",
        "\n",
        "# Sigmoid Kernel\n",
        "clf_sigmoid = svm.SVC(kernel = 'sigmoid')\n",
        "clf_sigmoid.fit(x_train, y_train)\n",
        "y_pred_sigmoid = clf_sigmoid.predict(x_test)\n",
        "\n",
        "acc_sigmoid = accuracy_score(y_test, y_pred_sigmoid)\n",
        "precision_sigmoid = precision_score(y_test, y_pred_sigmoid, average = 'macro')\n",
        "recall_sigmoid = recall_score(y_test, y_pred_sigmoid, average = 'macro')\n",
        "f1_sigmoid = f1_score(y_test, y_pred_sigmoid, average = 'macro')\n",
        "\n",
        "# Tao bang so sanh cac metrics Accuracy, Precision, Recall, F1\n",
        "tb = PrettyTable(['Kernel', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "\n",
        "tb.add_row(['Linear', acc_ln, precision_ln, recall_ln, f1_ln])\n",
        "tb.add_row(['Polynomial', acc_poly, precision_poly, recall_poly, f1_poly])\n",
        "tb.add_row(['Gaussian', acc_rbf, precision_rbf, recall_rbf, f1_rbf])\n",
        "tb.add_row(['Sigmoid', acc_sigmoid, precision_sigmoid, recall_sigmoid, f1_sigmoid])\n",
        "\n",
        "print(tb)"
      ],
      "metadata": {
        "id": "_xhPpF5b033h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "220489d0-e2a1-47c6-e175-3a340060881d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------------------+---------------------+--------------------+---------------------+\n",
            "|   Kernel   |       Accuracy      |      Precision      |       Recall       |          F1         |\n",
            "+------------+---------------------+---------------------+--------------------+---------------------+\n",
            "|   Linear   |         1.0         |         1.0         |        1.0         |         1.0         |\n",
            "| Polynomial |         1.0         |         1.0         |        1.0         |         1.0         |\n",
            "|  Gaussian  |  0.9777777777777777 |  0.9761904761904763 | 0.9777777777777779 |  0.9761600681140911 |\n",
            "|  Sigmoid   | 0.28888888888888886 | 0.09629629629629628 | 0.3333333333333333 | 0.14942528735632185 |\n",
            "+------------+---------------------+---------------------+--------------------+---------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "Compare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression) and SVM (using different kernels) with mnist dataset based on accuracy, precision, recall, f1 measures.\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "mnist = datasets.load_digits()\n",
        "x = mnist.data\n",
        "y = mnist.target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
        "# Decision Tree\n",
        "tree = DecisionTreeClassifier(random_state = 3)\n",
        "tree.fit(x_train, y_train)\n",
        "y_pred_tree = tree.predict(x_test)\n",
        "\n",
        "acc_tree = accuracy_score(y_test, y_pred_tree)\n",
        "precision_tree = precision_score(y_test, y_pred_tree, average = 'macro')\n",
        "recall_tree = recall_score(y_test, y_pred_tree, average = 'macro')\n",
        "f1_tree = f1_score(y_test, y_pred_tree, average = 'macro')\n",
        "\n",
        "# kNN\n",
        "kNN = KNeighborsClassifier()\n",
        "kNN.fit(x_train, y_train)\n",
        "y_pred_kNN = kNN.predict(x_test)\n",
        "\n",
        "acc_kNN = accuracy_score(y_test, y_pred_kNN)\n",
        "precision_kNN = precision_score(y_test, y_pred_kNN, average = 'macro')\n",
        "recall_kNN = recall_score(y_test, y_pred_kNN, average = 'macro')\n",
        "f1_kNN = f1_score(y_test, y_pred_kNN, average = 'macro')\n",
        "\n",
        "# Logistic Regression\n",
        "logistic = LogisticRegression(random_state = 3)\n",
        "logistic.fit(x_train, y_train)\n",
        "y_pred_logistic = logistic.predict(x_test)\n",
        "\n",
        "acc_logistic = accuracy_score(y_test, y_pred_logistic)\n",
        "precision_logistic = precision_score(y_test, y_pred_logistic, average = 'macro')\n",
        "recall_logistic = recall_score(y_test, y_pred_logistic, average = 'macro')\n",
        "f1_logistic = f1_score(y_test, y_pred_logistic, average = 'macro')\n",
        "\n",
        "# svm\n",
        "# Linear kernel\n",
        "clf_ln = svm.SVC(kernel = 'linear')\n",
        "clf_ln.fit(x_train, y_train)\n",
        "y_pred_ln = clf_ln.predict(x_test)\n",
        "\n",
        "acc_ln = accuracy_score(y_test, y_pred_ln)\n",
        "precision_ln = precision_score(y_test, y_pred_ln, average = 'macro')\n",
        "recall_ln = recall_score(y_test, y_pred_ln, average = 'macro')\n",
        "f1_ln = f1_score(y_test, y_pred_ln, average = 'macro')\n",
        "\n",
        "# Polynomial Kernel\n",
        "clf_poly = svm.SVC(kernel = 'poly')\n",
        "clf_poly.fit(x_train, y_train)\n",
        "y_pred_poly = clf_poly.predict(x_test)\n",
        "\n",
        "acc_poly = accuracy_score(y_test, y_pred_poly)\n",
        "precision_poly = precision_score(y_test, y_pred_poly, average = 'macro')\n",
        "recall_poly = recall_score(y_test, y_pred_poly, average = 'macro')\n",
        "f1_poly = f1_score(y_test, y_pred_poly, average = 'macro')\n",
        "\n",
        "# Gaussian Kernel\n",
        "clf_rbf = svm.SVC(kernel = 'rbf')\n",
        "clf_rbf.fit(x_train, y_train)\n",
        "y_pred_rbf = clf_rbf.predict(x_test)\n",
        "\n",
        "acc_rbf = accuracy_score(y_test, y_pred_rbf)\n",
        "precision_rbf = precision_score(y_test, y_pred_rbf, average = 'macro')\n",
        "recall_rbf = recall_score(y_test, y_pred_rbf, average = 'macro')\n",
        "f1_rbf = f1_score(y_test, y_pred_rbf, average = 'macro')\n",
        "\n",
        "# Sigmoid Kernel\n",
        "clf_sigmoid = svm.SVC(kernel = 'sigmoid')\n",
        "clf_sigmoid.fit(x_train, y_train)\n",
        "y_pred_sigmoid = clf_sigmoid.predict(x_test)\n",
        "\n",
        "acc_sigmoid = accuracy_score(y_test, y_pred_sigmoid)\n",
        "precision_sigmoid = precision_score(y_test, y_pred_sigmoid, average = 'macro')\n",
        "recall_sigmoid = recall_score(y_test, y_pred_sigmoid, average = 'macro')\n",
        "f1_sigmoid = f1_score(y_test, y_pred_sigmoid, average = 'macro')\n",
        "\n",
        "# Tao bang so sanh cac metrics Accuracy, Precision, Recall, F1\n",
        "tb = PrettyTable(['Thuat toan', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "\n",
        "table.add_row(['Tree', acc_tree, precision_tree, recall_tree, f1_tree])\n",
        "table.add_row(['kNN', acc_kNN, precision_kNN, recall_kNN, f1_kNN])\n",
        "table.add_row(['Logistic', acc_logistic, precision_logistic, recall_logistic, f1_logistic])\n",
        "tb.add_row(['Linear', acc_ln, precision_ln, recall_ln, f1_ln])\n",
        "tb.add_row(['Polynomial', acc_poly, precision_poly, recall_poly, f1_poly])\n",
        "tb.add_row(['Gaussian', acc_rbf, precision_rbf, recall_rbf, f1_rbf])\n",
        "tb.add_row(['Sigmoid', acc_sigmoid, precision_sigmoid, recall_sigmoid, f1_sigmoid])\n",
        "\n",
        "print(tb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IJsJfxixFHr",
        "outputId": "f1f67803-8a3d-42e0-c0e9-466c3bfb4e59"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------------------+--------------------+--------------------+--------------------+\n",
            "| Thuat toan |      Accuracy      |     Precision      |       Recall       |         F1         |\n",
            "+------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|   Linear   | 0.9777777777777777 | 0.9783618012422359 | 0.9804425478109688 | 0.9787063688116155 |\n",
            "| Polynomial | 0.9861111111111112 | 0.9860021092468912 | 0.9871092144776356 | 0.9863351661935079 |\n",
            "|  Gaussian  | 0.9833333333333333 | 0.9843698873282914 | 0.9844882681724787 | 0.9841459470611393 |\n",
            "|  Sigmoid   | 0.8972222222222223 | 0.8981837084831639 | 0.9009624183308393 | 0.8980183991020786 |\n",
            "+------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "Compare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression) and SVM (using different kernels) with **credit card dataset** based on accuracy, precision, recall, f1 measures.\n",
        "\n",
        "*   Give some comments on the obtained results\n",
        "*   Identify issues with dataset, and propose the solutions to these issues\n",
        "\n"
      ],
      "metadata": {
        "id": "Z5pp7_h-aP2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "dataSet = pd.read_csv(\"creditcard.csv\")\n",
        "dataSet = dataSet.head(10000)\n",
        "X = dataSet.drop('Class', axis =1)\n",
        "y = dataSet['Class']\n",
        "#Chuan hoa du lieu\n",
        "scaler = StandardScaler()\n",
        "X_scaler = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaler, y, test_size = 0.3)\n",
        "\n",
        "#logistic regression\n",
        "logistic = LogisticRegression(max_iter=1000)\n",
        "logistic.fit(X_train, y_train)\n",
        "y_pred_logistic = logistic.predict(X_test)\n",
        "#Knn Regression\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "#Decision Tree\n",
        "tree = DecisionTreeClassifier(criterion=\"gini\", random_state=42,\n",
        "max_depth=3, min_samples_leaf=5) \n",
        "tree.fit(X_train,y_train)\n",
        "y_predict_tree = tree.predict(X_test)\n",
        "#Linear Kernel\n",
        "clf = svm.SVC(kernel='linear') \n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_linear = clf.predict(X_test)\n",
        "\n",
        "#Polynomial Kernel\n",
        "clf = svm.SVC(kernel='poly') \n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_poly = clf.predict(X_test)\n",
        "#Radial Basis Function Kernel\n",
        "clf = svm.SVC(kernel='rbf') \n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_rbf = clf.predict(X_test)\n",
        "#Sigmoid Kernel\n",
        "clf = svm.SVC(kernel='sigmoid') \n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_sigmoid = clf.predict(X_test)\n",
        "\n",
        "t = PrettyTable([' ', 'accuracy','precision','recall','f1_score'])\n",
        "\n",
        "t.add_row(['Linear',accuracy_score(y_test, y_pred_linear),precision_score(y_test, y_pred_linear, average='macro',zero_division=1),recall_score(y_test, y_pred_linear, average='macro'),f1_score(y_test, y_pred_linear, average='macro')])\n",
        "t.add_row(['Polynomial',accuracy_score(y_test, y_pred_poly), precision_score(y_test, y_pred_poly, average='macro', zero_division=1),recall_score(y_test, y_pred_poly, average='macro'),f1_score(y_test, y_pred_poly, average='macro')])\n",
        "t.add_row(['Radial Basis Function',accuracy_score(y_test, y_pred_rbf), precision_score(y_test, y_pred_rbf, average='macro', zero_division=1), recall_score(y_test, y_pred_rbf, average='macro'),f1_score(y_test, y_pred_rbf, average='macro')])\n",
        "t.add_row(['Sigmoid', accuracy_score(y_test, y_pred_sigmoid),precision_score(y_test, y_pred_sigmoid, average='macro', zero_division=1),recall_score(y_test, y_pred_sigmoid, average='macro'),f1_score(y_test, y_pred_sigmoid, average='macro')])\n",
        "t.add_row(['KNN',accuracy_score(y_test, y_pred_knn), precision_score(y_test, y_pred_knn, average='macro', zero_division=1),recall_score(y_test, y_pred_knn, average='macro'),f1_score(y_test, y_pred_knn, average='macro')])\n",
        "t.add_row(['Logistic Regression',accuracy_score(y_test, y_pred_logistic), precision_score(y_test, y_pred_logistic, average='macro', zero_division=1), recall_score(y_test, y_pred_logistic, average='macro'),f1_score(y_test, y_pred_logistic, average='macro')])\n",
        "t.add_row(['Decision Tree', accuracy_score(y_test, y_predict_tree),precision_score(y_test, y_predict_tree, average='macro', zero_division=1),recall_score(y_test, y_predict_tree, average='macro'),f1_score(y_test, y_predict_tree, average='macro')])\n",
        "\n",
        "print(t)"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d2337a-0387-4619-a7a3-73e7a8fe2e9f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                       |      accuracy      |     precision      |       recall       |      f1_score      |\n",
            "+-----------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|         Linear        | 0.9983333333333333 | 0.8925222466749594 | 0.9225747469805052 | 0.9069888572651004 |\n",
            "|       Polynomial      |       0.998        |  0.90842178898385  | 0.8458190620895676 | 0.8744979919678715 |\n",
            "| Radial Basis Function |       0.998        | 0.9989976612094889 | 0.7692307692307692 | 0.8494983277591973 |\n",
            "|        Sigmoid        | 0.9956666666666667 | 0.7486622073578595 | 0.691470732146996  | 0.7163038022564759 |\n",
            "|          KNN          | 0.9986666666666667 | 0.9993313273152792 | 0.8461538461538461 | 0.9087563490373795 |\n",
            "|  Logistic Regression  | 0.9983333333333333 | 0.9161646586345382 | 0.8842806005511061 | 0.899581589958159  |\n",
            "|     Decision Tree     | 0.9993333333333333 | 0.9996654399464704 | 0.9230769230769231 | 0.9581659973226238 |\n",
            "+-----------------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}